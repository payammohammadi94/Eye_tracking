{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064b72b6-13d7-4b26-baaf-f335cd77d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "from math import hypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398d01a9-b22d-42dd-b714-a97bb94154e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "detector  = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"./shape_predictor_68_face_landmarks.dat\")\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "def midpoint(p1,p2):\n",
    "    return int((p1.x+p2.x)/2),int((p1.y+p2.y)/2)\n",
    "\n",
    "def landmark_eye(eye_position,landmarks):\n",
    "    left_point = (landmarks.part(eye_position[0]).x,landmarks.part(eye_position[0]).y)\n",
    "    right_point = (landmarks.part(eye_position[3]).x,landmarks.part(eye_position[3]).y)\n",
    "    center_top = midpoint(landmarks.part(eye_position[1]),landmarks.part(eye_position[2]))\n",
    "    center_bottom = midpoint(landmarks.part(eye_position[4]),landmarks.part(eye_position[5]))\n",
    "    \n",
    "    hor_line = cv2.line(frame,left_point,right_point,(0,0,255),2)\n",
    "    ver_line = cv2.line(frame,center_top,center_bottom,(0,255,0),2)\n",
    "    \n",
    "    hor_line_length = hypot((left_point[0] - right_point[0]),(left_point[1] - right_point[1]))\n",
    "    ver_line_length = hypot((center_bottom[0]-center_top[0]),(center_bottom[1]-center_top[1]))\n",
    "    \n",
    "    ratio = hor_line_length / ver_line_length\n",
    "\n",
    "    return ratio \n",
    "while(cap.isOpened()):  # check !\n",
    "    # capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret: # check ! (some webcam's need a \"warmup\")\n",
    "        # our operation on frame come here\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "        for face in faces:\n",
    "            #left, top = face.left(),face.top()\n",
    "            #right,bottom = face.right(),face.bottom()\n",
    "            #cv2.rectangle(frame, (left, top),(right,bottom),(0,255,0),2)\n",
    "\n",
    "            landmarks = predictor(gray,face)\n",
    "            \n",
    "            ratio_left = landmark_eye([36,37,38,39,40,41],landmarks)\n",
    "            ratio_right = landmark_eye([42,43,44,45,46,47],landmarks)\n",
    "            \n",
    "            ratio = (ratio_left+ratio_right)/2\n",
    "            if ratio > 5.7:\n",
    "                cv2.putText(frame,\"OOOOFFFF\",(50,150),font,7,(255,0,0))\n",
    "            #cv2.circle(frame,(x36,y39),3,(0,0,255),2)\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# When everything is done release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe383c25-7069-40ae-967e-bd89152b1652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bcec73-f6e7-4294-9545-d48a1266ed1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
